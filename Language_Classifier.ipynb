{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "Language Classifier.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Aw4JEynLXTd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import string\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvMzrxENLXTl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = pd.read_csv('dataset.csv')"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17XckL12LXTr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "languages = list(set(dataset['language']))\n",
        "data_raw = dict()\n",
        "a = dataset.groupby('language')\n",
        "for l in languages:\n",
        "    d = a.get_group(l)\n",
        "    d.drop('language',axis=1,inplace=True)\n",
        "    t = d.Text.str.cat(sep=\"\\n\")\n",
        "    t = t.split('\\n')\n",
        "    data_raw[l] = t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHGjXqP3LXTv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_statistics(data):\n",
        "    for language, sentences in data.items():\n",
        "        \n",
        "        word_list = ' '.join(sentences).split()\n",
        "        number_of_sentences = len(sentences)\n",
        "        number_of_words = len(word_list)\n",
        "        number_of_unique_words = len(set(word_list))\n",
        "        sample_extract = \" \".join(sentences[0].split()[0:7])\n",
        "        \n",
        "        print(f'Language: {language}')\n",
        "        print('-----------------------')\n",
        "        print(f'Number of sentences\\t:\\t {number_of_sentences}')\n",
        "        print(f'Number of words\\t\\t:\\t {number_of_words}')\n",
        "        print(f'Number of unique words\\t:\\t {number_of_unique_words}')\n",
        "        print(f'Sample extract\\t\\t:\\t {sample_extract}...\\n')"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzZUC8N-LXTy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2f2e7b5a-d1bb-4856-c83b-1e07ed9c3d4e"
      },
      "source": [
        "show_statistics(data_raw)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Language: Tamil\n",
            "-----------------------\n",
            "Number of sentences\t:\t 1000\n",
            "Number of words\t\t:\t 38615\n",
            "Number of unique words\t:\t 17159\n",
            "Sample extract\t\t:\t விசாகப்பட்டினம் தமிழ்ச்சங்கத்தை இந்துப் பத்திரிகை-விசாகப்பட்டின ஆசிரியர் சம்பத்துடன் இணைந்து...\n",
            "\n",
            "Language: Persian\n",
            "-----------------------\n",
            "Number of sentences\t:\t 1000\n",
            "Number of words\t\t:\t 77553\n",
            "Number of unique words\t:\t 12616\n",
            "Sample extract\t\t:\t آهن ترکیباتی را ایجاد می‌کند که عمدتاً...\n",
            "\n",
            "Language: Latin\n",
            "-----------------------\n",
            "Number of sentences\t:\t 1000\n",
            "Number of words\t\t:\t 42191\n",
            "Number of unique words\t:\t 14671\n",
            "Sample extract\t\t:\t müller mox figura centralis circulorum doctorum vindobonesium...\n",
            "\n",
            "Language: Romanian\n",
            "-----------------------\n",
            "Number of sentences\t:\t 1000\n",
            "Number of words\t\t:\t 52858\n",
            "Number of unique words\t:\t 13293\n",
            "Sample extract\t\t:\t de-a lungul vieții watson a fost interesat...\n",
            "\n",
            "Language: Turkish\n",
            "-----------------------\n",
            "Number of sentences\t:\t 1000\n",
            "Number of words\t\t:\t 49914\n",
            "Number of unique words\t:\t 18199\n",
            "Sample extract\t\t:\t tsutinalar i̇ngilizce tsuutina kanadada alberta bölgesinde calgaryde...\n",
            "\n",
            "Language: Pushto\n",
            "-----------------------\n",
            "Number of sentences\t:\t 1000\n",
            "Number of words\t\t:\t 95446\n",
            "Number of unique words\t:\t 20114\n",
            "Sample extract\t\t:\t لویي په کالونیو کې د ظلم کولو...\n",
            "\n",
            "Language: Thai\n",
            "-----------------------\n",
            "Number of sentences\t:\t 1000\n",
            "Number of words\t\t:\t 17378\n",
            "Number of unique words\t:\t 12893\n",
            "Sample extract\t\t:\t ถนนเจริญกรุง อักษรโรมัน thanon charoen krung เริ่มตั้งแต่ถนนสนามไชยถึงแม่น้ำเจ้าพระยาที่ถนนตก กรุงเทพมหานคร...\n",
            "\n",
            "Language: Russian\n",
            "-----------------------\n",
            "Number of sentences\t:\t 1000\n",
            "Number of words\t\t:\t 53029\n",
            "Number of unique words\t:\t 18495\n",
            "Sample extract\t\t:\t занимает пятое место в диптихе автокефальных поместных...\n",
            "\n",
            "Language: Spanish\n",
            "-----------------------\n",
            "Number of sentences\t:\t 1000\n",
            "Number of words\t\t:\t 64452\n",
            "Number of unique words\t:\t 12566\n",
            "Sample extract\t\t:\t en navidad de poco después de que...\n",
            "\n",
            "Language: Arabic\n",
            "-----------------------\n",
            "Number of sentences\t:\t 1000\n",
            "Number of words\t\t:\t 69273\n",
            "Number of unique words\t:\t 21892\n",
            "Sample extract\t\t:\t قبل عام بالضبط وبتاريخ أعلن البغدادي خطة...\n",
            "\n",
            "Language: French\n",
            "-----------------------\n",
            "Number of sentences\t:\t 1000\n",
            "Number of words\t\t:\t 63779\n",
            "Number of unique words\t:\t 12458\n",
            "Sample extract\t\t:\t association de recherche et de sauvegarde de...\n",
            "\n",
            "Language: Estonian\n",
            "-----------------------\n",
            "Number of sentences\t:\t 1000\n",
            "Number of words\t\t:\t 38390\n",
            "Number of unique words\t:\t 16421\n",
            "Sample extract\t\t:\t klement gottwaldi surnukeha palsameeriti ning paigutati mausoleumi...\n",
            "\n",
            "Language: English\n",
            "-----------------------\n",
            "Number of sentences\t:\t 1000\n",
            "Number of words\t\t:\t 67623\n",
            "Number of unique words\t:\t 12338\n",
            "Sample extract\t\t:\t in johnson was awarded an american institute...\n",
            "\n",
            "Language: Chinese\n",
            "-----------------------\n",
            "Number of sentences\t:\t 1000\n",
            "Number of words\t\t:\t 3196\n",
            "Number of unique words\t:\t 2629\n",
            "Sample extract\t\t:\t 胡赛尼本人和小说的主人公阿米尔一样，都是出生在阿富汗首都喀布尔，少年时代便离开了这个国家。胡赛尼直到年小说出版之后才首次回到已经离开年的祖国。他在苏联入侵时离开了阿富汗，而他的很多童年好友在阿富汗生活艰难，还有一些表亲离开人世，其中一位在童年时代和他一起放风筝的表兄弟就是在逃离阿富汗时死在了油罐车中（这一情节在《追风筝的人》中也有描写），而这位表兄弟的父亲也被人枪杀；因此胡赛尼总是怀有幸存者所特有的一种内疚心态，这种情感在小说中也有体现。很多人因此认为这部小说有些自传色彩。胡赛尼则表示小说中确实有一部分内容是根据自己的经历创作的，他和故事主人公也有很多相似点，但是一些内容被他刻意地模糊处理了。尽管和主人公的经历有诸多的相似点，胡赛尼仍然坚称小说情节确实是虚构的。之后胡赛尼在创作他的第二部小说《灿烂千阳》时把主人公设定为女性，称“这样应该就能一劳永逸地解决人们关于‘自传’的问题了”。...\n",
            "\n",
            "Language: Japanese\n",
            "-----------------------\n",
            "Number of sentences\t:\t 1000\n",
            "Number of words\t\t:\t 3131\n",
            "Number of unique words\t:\t 2580\n",
            "Sample extract\t\t:\t エノが行きがかりでバスに乗ってしまい、気分が悪くなった際に助けるが、今すぐバスを降りたいと運転手に頼む際、本当のことを言ってしまうと彼女が恥ずかしい思いをすると察して「僕ウンコしたいんです」と言ってバスを降りた。エノは内心「私もしたいみたいじゃないの」と思うも、別れ際にエノの髪を「ふわふわのお菓子みたい」と言い、この台詞に憧れていたエノに強い衝撃を与えた。この話を聞いたリコは、以後彼のことを『ウンコ王子』または『ウンコ』というあだ名で呼ぶようになったが、エノは普通に「戸田くん」と呼んでいる。...\n",
            "\n",
            "Language: Hindi\n",
            "-----------------------\n",
            "Number of sentences\t:\t 1000\n",
            "Number of words\t\t:\t 85553\n",
            "Number of unique words\t:\t 13916\n",
            "Sample extract\t\t:\t महाराष्ट्र मई को भारत का राज्य बनाया...\n",
            "\n",
            "Language: Korean\n",
            "-----------------------\n",
            "Number of sentences\t:\t 1000\n",
            "Number of words\t\t:\t 62246\n",
            "Number of unique words\t:\t 29058\n",
            "Sample extract\t\t:\t 한국에서 성씨가 사용되기 시작한 정확한 시기는 알...\n",
            "\n",
            "Language: Dutch\n",
            "-----------------------\n",
            "Number of sentences\t:\t 1000\n",
            "Number of words\t\t:\t 53178\n",
            "Number of unique words\t:\t 11673\n",
            "Sample extract\t\t:\t de spons behoort tot het geslacht haliclona...\n",
            "\n",
            "Language: Indonesian\n",
            "-----------------------\n",
            "Number of sentences\t:\t 1000\n",
            "Number of words\t\t:\t 54806\n",
            "Number of unique words\t:\t 10562\n",
            "Sample extract\t\t:\t kemunculan pertamanya adalah ketika mencium kakak kelasnya...\n",
            "\n",
            "Language: Urdu\n",
            "-----------------------\n",
            "Number of sentences\t:\t 1000\n",
            "Number of words\t\t:\t 68474\n",
            "Number of unique words\t:\t 12335\n",
            "Sample extract\t\t:\t برقی بار electric charge تمام زیرجوہری ذرات...\n",
            "\n",
            "Language: Portugese\n",
            "-----------------------\n",
            "Number of sentences\t:\t 1000\n",
            "Number of words\t\t:\t 63456\n",
            "Number of unique words\t:\t 12895\n",
            "Sample extract\t\t:\t barocco pt escândalo de ª página é...\n",
            "\n",
            "Language: Swedish\n",
            "-----------------------\n",
            "Number of sentences\t:\t 1000\n",
            "Number of words\t\t:\t 48442\n",
            "Number of unique words\t:\t 8611\n",
            "Sample extract\t\t:\t sebes joseph pereira thomas på eng the...\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WruDzUX6LXT2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(text):   \n",
        "    preprocessed_text = text.lower().replace('-', ' ')\n",
        "    \n",
        "    translation_table = str.maketrans('\\n', ' ', string.punctuation+string.digits)\n",
        "    \n",
        "    preprocessed_text = preprocessed_text.translate(translation_table)\n",
        "        \n",
        "    return preprocessed_text"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQLAw4_jLXT5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_preprocessed = {k: [preprocess(sentence) for sentence in v] for k, v in data_raw.items()}"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uty8eBIrLXT9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9d30e3ae-26b9-4538-e683-836c71aa4f94"
      },
      "source": [
        "show_statistics(data_preprocessed)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Language: Tamil\n",
            "-----------------------\n",
            "Number of sentences\t:\t 1000\n",
            "Number of words\t\t:\t 38627\n",
            "Number of unique words\t:\t 17078\n",
            "Sample extract\t\t:\t விசாகப்பட்டினம் தமிழ்ச்சங்கத்தை இந்துப் பத்திரிகை விசாகப்பட்டின ஆசிரியர் சம்பத்துடன்...\n",
            "\n",
            "Language: Persian\n",
            "-----------------------\n",
            "Number of sentences\t:\t 1000\n",
            "Number of words\t\t:\t 77548\n",
            "Number of unique words\t:\t 12567\n",
            "Sample extract\t\t:\t آهن ترکیباتی را ایجاد می‌کند که عمدتاً...\n",
            "\n",
            "Language: Latin\n",
            "-----------------------\n",
            "Number of sentences\t:\t 1000\n",
            "Number of words\t\t:\t 42252\n",
            "Number of unique words\t:\t 14538\n",
            "Sample extract\t\t:\t müller mox figura centralis circulorum doctorum vindobonesium...\n",
            "\n",
            "Language: Romanian\n",
            "-----------------------\n",
            "Number of sentences\t:\t 1000\n",
            "Number of words\t\t:\t 53662\n",
            "Number of unique words\t:\t 13088\n",
            "Sample extract\t\t:\t de a lungul vieții watson a fost...\n",
            "\n",
            "Language: Turkish\n",
            "-----------------------\n",
            "Number of sentences\t:\t 1000\n",
            "Number of words\t\t:\t 49978\n",
            "Number of unique words\t:\t 17933\n",
            "Sample extract\t\t:\t tsutinalar i̇ngilizce tsuutina kanadada alberta bölgesinde calgaryde...\n",
            "\n",
            "Language: Pushto\n",
            "-----------------------\n",
            "Number of sentences\t:\t 1000\n",
            "Number of words\t\t:\t 95115\n",
            "Number of unique words\t:\t 19959\n",
            "Sample extract\t\t:\t لویي په کالونیو کې د ظلم کولو...\n",
            "\n",
            "Language: Thai\n",
            "-----------------------\n",
            "Number of sentences\t:\t 1000\n",
            "Number of words\t\t:\t 17403\n",
            "Number of unique words\t:\t 12876\n",
            "Sample extract\t\t:\t ถนนเจริญกรุง อักษรโรมัน thanon charoen krung เริ่มตั้งแต่ถนนสนามไชยถึงแม่น้ำเจ้าพระยาที่ถนนตก กรุงเทพมหานคร...\n",
            "\n",
            "Language: Russian\n",
            "-----------------------\n",
            "Number of sentences\t:\t 1000\n",
            "Number of words\t\t:\t 53539\n",
            "Number of unique words\t:\t 18477\n",
            "Sample extract\t\t:\t занимает пятое место в диптихе автокефальных поместных...\n",
            "\n",
            "Language: Spanish\n",
            "-----------------------\n",
            "Number of sentences\t:\t 1000\n",
            "Number of words\t\t:\t 64476\n",
            "Number of unique words\t:\t 12352\n",
            "Sample extract\t\t:\t en navidad de poco después de que...\n",
            "\n",
            "Language: Arabic\n",
            "-----------------------\n",
            "Number of sentences\t:\t 1000\n",
            "Number of words\t\t:\t 69134\n",
            "Number of unique words\t:\t 21528\n",
            "Sample extract\t\t:\t قبل عام بالضبط وبتاريخ أعلن البغدادي خطة...\n",
            "\n",
            "Language: French\n",
            "-----------------------\n",
            "Number of sentences\t:\t 1000\n",
            "Number of words\t\t:\t 64567\n",
            "Number of unique words\t:\t 12246\n",
            "Sample extract\t\t:\t association de recherche et de sauvegarde de...\n",
            "\n",
            "Language: Estonian\n",
            "-----------------------\n",
            "Number of sentences\t:\t 1000\n",
            "Number of words\t\t:\t 38743\n",
            "Number of unique words\t:\t 16219\n",
            "Sample extract\t\t:\t klement gottwaldi surnukeha palsameeriti ning paigutati mausoleumi...\n",
            "\n",
            "Language: English\n",
            "-----------------------\n",
            "Number of sentences\t:\t 1000\n",
            "Number of words\t\t:\t 68274\n",
            "Number of unique words\t:\t 11531\n",
            "Sample extract\t\t:\t in johnson was awarded an american institute...\n",
            "\n",
            "Language: Chinese\n",
            "-----------------------\n",
            "Number of sentences\t:\t 1000\n",
            "Number of words\t\t:\t 3349\n",
            "Number of unique words\t:\t 2766\n",
            "Sample extract\t\t:\t 胡赛尼本人和小说的主人公阿米尔一样，都是出生在阿富汗首都喀布尔，少年时代便离开了这个国家。胡赛尼直到年小说出版之后才首次回到已经离开年的祖国。他在苏联入侵时离开了阿富汗，而他的很多童年好友在阿富汗生活艰难，还有一些表亲离开人世，其中一位在童年时代和他一起放风筝的表兄弟就是在逃离阿富汗时死在了油罐车中（这一情节在《追风筝的人》中也有描写），而这位表兄弟的父亲也被人枪杀；因此胡赛尼总是怀有幸存者所特有的一种内疚心态，这种情感在小说中也有体现。很多人因此认为这部小说有些自传色彩。胡赛尼则表示小说中确实有一部分内容是根据自己的经历创作的，他和故事主人公也有很多相似点，但是一些内容被他刻意地模糊处理了。尽管和主人公的经历有诸多的相似点，胡赛尼仍然坚称小说情节确实是虚构的。之后胡赛尼在创作他的第二部小说《灿烂千阳》时把主人公设定为女性，称“这样应该就能一劳永逸地解决人们关于‘自传’的问题了”。...\n",
            "\n",
            "Language: Japanese\n",
            "-----------------------\n",
            "Number of sentences\t:\t 1000\n",
            "Number of words\t\t:\t 3155\n",
            "Number of unique words\t:\t 2725\n",
            "Sample extract\t\t:\t エノが行きがかりでバスに乗ってしまい、気分が悪くなった際に助けるが、今すぐバスを降りたいと運転手に頼む際、本当のことを言ってしまうと彼女が恥ずかしい思いをすると察して「僕ウンコしたいんです」と言ってバスを降りた。エノは内心「私もしたいみたいじゃないの」と思うも、別れ際にエノの髪を「ふわふわのお菓子みたい」と言い、この台詞に憧れていたエノに強い衝撃を与えた。この話を聞いたリコは、以後彼のことを『ウンコ王子』または『ウンコ』というあだ名で呼ぶようになったが、エノは普通に「戸田くん」と呼んでいる。...\n",
            "\n",
            "Language: Hindi\n",
            "-----------------------\n",
            "Number of sentences\t:\t 1000\n",
            "Number of words\t\t:\t 85856\n",
            "Number of unique words\t:\t 13526\n",
            "Sample extract\t\t:\t महाराष्ट्र मई को भारत का राज्य बनाया...\n",
            "\n",
            "Language: Korean\n",
            "-----------------------\n",
            "Number of sentences\t:\t 1000\n",
            "Number of words\t\t:\t 62256\n",
            "Number of unique words\t:\t 28904\n",
            "Sample extract\t\t:\t 한국에서 성씨가 사용되기 시작한 정확한 시기는 알...\n",
            "\n",
            "Language: Dutch\n",
            "-----------------------\n",
            "Number of sentences\t:\t 1000\n",
            "Number of words\t\t:\t 53590\n",
            "Number of unique words\t:\t 11487\n",
            "Sample extract\t\t:\t de spons behoort tot het geslacht haliclona...\n",
            "\n",
            "Language: Indonesian\n",
            "-----------------------\n",
            "Number of sentences\t:\t 1000\n",
            "Number of words\t\t:\t 55437\n",
            "Number of unique words\t:\t 10160\n",
            "Sample extract\t\t:\t kemunculan pertamanya adalah ketika mencium kakak kelasnya...\n",
            "\n",
            "Language: Urdu\n",
            "-----------------------\n",
            "Number of sentences\t:\t 1000\n",
            "Number of words\t\t:\t 68605\n",
            "Number of unique words\t:\t 12274\n",
            "Sample extract\t\t:\t برقی بار electric charge تمام زیرجوہری ذرات...\n",
            "\n",
            "Language: Portugese\n",
            "-----------------------\n",
            "Number of sentences\t:\t 1000\n",
            "Number of words\t\t:\t 63908\n",
            "Number of unique words\t:\t 12496\n",
            "Sample extract\t\t:\t barocco pt escândalo de ª página é...\n",
            "\n",
            "Language: Swedish\n",
            "-----------------------\n",
            "Number of sentences\t:\t 1000\n",
            "Number of words\t\t:\t 48628\n",
            "Number of unique words\t:\t 8567\n",
            "Sample extract\t\t:\t sebes joseph pereira thomas på eng the...\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLTXliAsLXUB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences_train, y_train = [], []\n",
        "\n",
        "for k, v in data_preprocessed.items():\n",
        "    for sentence in v:\n",
        "        sentences_train.append(sentence)\n",
        "        y_train.append(k)"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEeiTGu7LXUF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectorizer = CountVectorizer()"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXZAXab2LXUI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = vectorizer.fit_transform(sentences_train)"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_WpDar7LXUL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4fa10f0c-e53a-44ce-cbef-8569567522bb"
      },
      "source": [
        "naive_classifier = MultinomialNB(alpha=0.0001,fit_prior=False)\n",
        "naive_classifier.fit(X_train, y_train)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=0.0001, class_prior=None, fit_prior=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KmiZJGKoflu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aeca5b9b-fd50-4c4b-dedc-5a70c245bd33"
      },
      "source": [
        "text = 'मेरा नाम है श्रेयश देशपांडे '\n",
        "text = preprocess(text)\n",
        "text = [text]\n",
        "text_v = vectorizer.transform(text)\n",
        "print(naive_classifier.predict(text_v))"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Hindi']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58sHjBL5xqlY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
